
# ğŸ³ Infraestrutura Local â€“ Desafio Kafka + MongoDB

Este guia mostra como subir, parar e acessar a infraestrutura necessÃ¡ria para o desafio tÃ©cnico (MongoDB + Mongo Express + Kafka + Kafka UI) usando **Docker Compose** no WSL.

---

## ğŸš€ Subindo a infra

Dentro da pasta `~/infra-desafio`:

```bash
# subir em background
docker compose up -d
```

Ver containers ativos:

```bash
docker ps
```

---

## â¹ï¸ Parando a infra



```bash
docker compose down
```

---

## ğŸ“‚ ServiÃ§os disponÃ­veis

### 1. **MongoDB**

* **Host**: `localhost`
* **Porta**: `27017`
* **Database default para o projeto**: `desafio`
* **String de conexÃ£o (Spring Boot)**:

  ```
  spring.data.mongodb.uri=mongodb://localhost:27017/desafio
  ```

ğŸ”§ Como usar:

* A aplicaÃ§Ã£o Java conecta direto nessa URI.
* Para acessar via shell dentro do container:

  ```bash
  docker exec -it desafio-mongo mongosh
  ```
* Comandos bÃ¡sicos no `mongosh`:

  ```mongodb
  show dbs
  use desafio
  show collections
  db.usuarios.find()
  ```

---

### 2. **Mongo Express (UI para MongoDB)**

* **URL**: [http://localhost:8081](http://localhost:8081)
* **UsuÃ¡rio**: `admin`
* **Senha**: `admin`

ğŸ”§ Como usar:

* Login com `admin/admin`.
* Navegar pelas bases e coleÃ§Ãµes criadas pela aplicaÃ§Ã£o.
* Inserir, editar e deletar documentos manualmente (apenas para teste/dev).

---

### 3. **Zookeeper**

* **Porta**: `2181`
* Usado apenas como dependÃªncia do Kafka.
* VocÃª **nÃ£o precisa interagir** diretamente com ele.

---

### 4. **Kafka (Broker)**

* **Broker**: `localhost:9092`

ğŸ”§ Como usar:

* Ainda nÃ£o serÃ¡ usado pelo primeiro microsserviÃ§o (API Insert).
* SerÃ¡ usado depois pelo Writer/Search.
* Teste de tÃ³picos (apenas curiosidade):

  ```bash
  docker exec -it desafio-kafka kafka-topics --bootstrap-server localhost:9092 --list
  ```

---

### 5. **Kafka UI (Interface web para Kafka)**

* **URL**: [http://localhost:8080](http://localhost:8080)

ğŸ”§ Como usar:

* Painel web para visualizar brokers, tÃ³picos e mensagens.
* VocÃª poderÃ¡ ver quando os serviÃ§os Writer/Search comeÃ§arem a produzir/consumir mensagens.

---

## ğŸ“ Fluxo esperado do projeto

1. **API Insert** (Java, local via IntelliJ) â†’ conecta no Mongo (`localhost:27017`) e salva dados em `usuarios`.
2. **Mongo Express** â†’ permite vocÃª visualizar em tempo real os documentos inseridos.
3. **Kafka/Kafka UI** â†’ ficam prontos para a segunda fase (outros microsserviÃ§os).

---

## âš ï¸ Notas importantes

* **PersistÃªncia**: o volume `mongo_data` garante que os dados no Mongo sobrevivam mesmo com `docker compose down`.
* **Senhas fracas**: `admin/admin` Ã© sÃ³ para desenvolvimento.
* **Ordem de inicializaÃ§Ã£o**: Mongo deve subir antes da aplicaÃ§Ã£o Java, mas o Docker Compose jÃ¡ cuida disso.

---

## ğŸ Ciclo rÃ¡pido de trabalho

1. Subir a infra:

   ```bash
   docker compose up -d
   ```
2. Rodar a aplicaÃ§Ã£o no IntelliJ (Java â†’ Spring Boot).
3. Testar endpoints da API com `curl` ou Postman.
4. Conferir coleÃ§Ãµes no [Mongo Express](http://localhost:8081).
5. (Mais tarde) Monitorar mensagens no [Kafka UI](http://localhost:8080).

